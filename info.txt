ðŸš€ Roadmap Projeto: Weather Data Pipeline com MongoDB
ðŸ”¹ Fase 1 â€“ Setup do Ambiente
Objetivo: Preparar seu ambiente local ou em nuvem para desenvolvimento.

Tarefas:

 Criar ambiente virtual Python (venv ou conda)

 Instalar MongoDB localmente ou criar instÃ¢ncia no MongoDB Atlas (recomendado)

 Instalar:

Python 3.10+

pymongo, requests, airflow, pyspark, pandas, streamlit

 Subir o Airflow com Docker ou ambiente local

 Criar projeto estruturado:

pgsql
Copiar
Editar
/weather_pipeline
â”œâ”€â”€ dags/
â”œâ”€â”€ extract/
â”œâ”€â”€ transform/
â”œâ”€â”€ load/
â”œâ”€â”€ dashboard/
â”œâ”€â”€ configs/
â””â”€â”€ logs/
ðŸ”¹ Fase 2 â€“ ExtraÃ§Ã£o (Python + OpenWeatherAPI)
Objetivo: Consumir e salvar os dados brutos da OpenWeatherAPI.

Tarefas:

 Criar conta e chave na OpenWeather

 Criar script Python para:

RequisiÃ§Ã£o para API (por cidade, coordenada ou grupo de cidades)

Salvar como JSON localmente ou enviar direto para MongoDB

 Salvar os dados brutos em uma pasta /raw_data ou coleÃ§Ã£o raw_weather

Entrega: Script funcional para extrair dados e salvÃ¡-los.

ðŸ”¹ Fase 3 â€“ OrquestraÃ§Ã£o (Airflow)
Objetivo: Automatizar a pipeline de ETL.

Tarefas:

 Criar DAG no Airflow:

Task 1: Executar extraÃ§Ã£o (script Python)

Task 2: Chamar transformaÃ§Ã£o com PySpark

Task 3: Carregar dados no MongoDB

 Configurar a DAG para rodar a cada hora/dia

Entrega: DAG funcionando com logs e falhas rastreÃ¡veis.

ðŸ”¹ Fase 4 â€“ TransformaÃ§Ã£o e ValidaÃ§Ã£o (PySpark)
Objetivo: Limpar, transformar e preparar os dados.

Tarefas:

 Carregar JSON com Spark

 Validar campos (ex: temperatura, umidade, coordenadas)

 Converter datas e normalizar unidades

 Agregar dados por cidade/data (se quiser)

 Salvar dataset limpo para carga no MongoDB

Entrega: Script PySpark funcional para processar dados.

ðŸ”¹ Fase 5 â€“ Carga no MongoDB
Objetivo: Inserir os dados validados em uma coleÃ§Ã£o MongoDB.

Tarefas:

 Usar pymongo ou spark-mongodb-connector para enviar dados para MongoDB

 Criar Ã­ndices (por cidade, timestamp)

 Separar coleÃ§Ãµes se quiser (ex: weather_raw, weather_cleaned)

Entrega: Banco MongoDB com dados prontos para consulta.

ðŸ”¹ Fase 6 â€“ Dashboard Interativo (Streamlit ou Dash)
Objetivo: Criar interface interativa para anÃ¡lise dos dados.

Tarefas:

 Consultar dados do MongoDB em tempo real

 Criar filtros por cidade, data, temperatura etc.

 Exibir:

GrÃ¡ficos de variaÃ§Ã£o de temperatura

Mapa com localizaÃ§Ã£o das cidades (opcional)

TendÃªncia de clima por hora/dia

 Deploy no Streamlit Cloud ou Heroku

Entrega: Dashboard funcional acessÃ­vel pela web.